{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Common Spatial Patterns (CSP) feature extraction - basically learns where on the scalp to \"look\" for each movement type -> able to maximize variance ratio between classes\n",
    "2. LDA classifier (baseline)\n",
    "3. SVM classifier (improved)\n",
    "4. Within-subject and cross-subject evaluation\n",
    "5. Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mne\n",
    "from mne.decoding import CSP\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from features import CSPFeatures, compute_csp_features\n",
    "from models import create_lda_pipeline, create_svm_pipeline, evaluate_classifier\n",
    "from visualization import set_style, plot_confusion_matrix, plot_subject_comparison, CLASS_NAMES\n",
    "from preprocessing import CHANNEL_NAMES\n",
    "\n",
    "set_style()\n",
    "np.random.seed(42)\n",
    "\n",
    "PROCESSED_DIR = Path('../data/processed')\n",
    "RESULTS_DIR = Path('../results')\n",
    "FIGURES_DIR = Path('../figures')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "FIGURES_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "data_path = PROCESSED_DIR / 'preprocessed_data.npz'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(\"Run notebook 02_preprocessing.ipynb first!\")\n",
    "\n",
    "data = np.load(data_path, allow_pickle=True)\n",
    "\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "subjects_train = data['subjects_train']\n",
    "\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']\n",
    "subjects_test = data['subjects_test']\n",
    "\n",
    "print(f\"Training data: {X_train.shape}\")\n",
    "print(f\"Test data: {X_test.shape}\")\n",
    "print(f\"Classes: {np.unique(y_train)} -> {CLASS_NAMES}\")\n",
    "print(f\"Subjects: {np.unique(subjects_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variance of W·X is max for class 1\n",
    "- Variance of W·X is min for class 2\n",
    "\n",
    "- Left hand imagery → decreased mu/beta power over RIGHT motor cortex (C4)\n",
    "- Right hand imagery → decreased mu/beta power over LEFT motor cortex (C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate CSP on a single subject (binary: left vs right hand)\n",
    "subj = 1\n",
    "mask_train = (subjects_train == subj) & ((y_train == 0) | (y_train == 1))  # Left vs Right only\n",
    "mask_test = (subjects_test == subj) & ((y_test == 0) | (y_test == 1))\n",
    "\n",
    "X_subj_train = X_train[mask_train]\n",
    "y_subj_train = y_train[mask_train]\n",
    "X_subj_test = X_test[mask_test]\n",
    "y_subj_test = y_test[mask_test]\n",
    "\n",
    "print(f\"Subject {subj} - Left vs Right hand:\")\n",
    "print(f\"  Train: {X_subj_train.shape[0]} trials\")\n",
    "print(f\"  Test: {X_subj_test.shape[0]} trials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit CSP\n",
    "csp_binary = CSP(n_components=4, reg='ledoit_wolf', log=True, norm_trace=True)\n",
    "csp_binary.fit(X_subj_train, y_subj_train)\n",
    "\n",
    "# Transform data\n",
    "X_train_csp = csp_binary.transform(X_subj_train)\n",
    "X_test_csp = csp_binary.transform(X_subj_test)\n",
    "\n",
    "print(f\"Original shape: {X_subj_train.shape} -> CSP features: {X_train_csp.shape}\")\n",
    "print(f\"Reduced from {22 * 875} = {22*875} features to {X_train_csp.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CSP patterns (what the filters \"look\" for)\n",
    "info = mne.create_info(ch_names=CHANNEL_NAMES, sfreq=250, ch_types='eeg')\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "info.set_montage(montage)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
    "\n",
    "for idx in range(4):\n",
    "    pattern = csp_binary.patterns_[idx]\n",
    "    mne.viz.plot_topomap(pattern, info, axes=axes[idx], show=False)\n",
    "    axes[idx].set_title(f'CSP {idx+1}')\n",
    "\n",
    "fig.suptitle('CSP Spatial Patterns (Left vs Right Hand)', y=1.05, fontsize=14)\n",
    "plt.tight_layout();\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- First 2 patterns: maximize variance for one class\")\n",
    "print(\"- Last 2 patterns: maximize variance for other class\")\n",
    "print(\"- Look for lateralization over motor cortex (C3/C4 area)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CSP features separation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Scatter plot of first two CSP components\n",
    "colors = ['blue', 'red']\n",
    "labels = ['Left Hand', 'Right Hand']\n",
    "\n",
    "for cls in [0, 1]:\n",
    "    mask = y_subj_train == cls\n",
    "    axes[0].scatter(X_train_csp[mask, 0], X_train_csp[mask, 1], \n",
    "                    c=colors[cls], label=labels[cls], alpha=0.6, s=40)\n",
    "\n",
    "axes[0].set_xlabel('CSP Component 1 (log-var)')\n",
    "axes[0].set_ylabel('CSP Component 2 (log-var)')\n",
    "axes[0].set_title('CSP Feature Space (Training)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot of all components\n",
    "csp_data = []\n",
    "for comp in range(4):\n",
    "    for cls in [0, 1]:\n",
    "        mask = y_subj_train == cls\n",
    "        for val in X_train_csp[mask, comp]:\n",
    "            csp_data.append({'Component': f'CSP {comp+1}', 'Class': labels[cls], 'Value': val})\n",
    "\n",
    "import pandas as pd\n",
    "df_csp = pd.DataFrame(csp_data)\n",
    "sns.boxplot(data=df_csp, x='Component', y='Value', hue='Class', ax=axes[1], palette=['blue', 'red'])\n",
    "axes[1].set_title('CSP Feature Distribution by Class')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within subject classification (train and test on the same subject)\n",
    "def evaluate_subject(subj_id, X_train, y_train, subjects_train, \n",
    "                     X_test, y_test, subjects_test, n_components=6):\n",
    "    \"\"\"\n",
    "    Evaluate CSP+classifier on a single subject.\n",
    "    \n",
    "    Returns dict with results for LDA and SVM.\n",
    "    \"\"\"\n",
    "    # Get subject data\n",
    "    mask_train = subjects_train == subj_id\n",
    "    mask_test = subjects_test == subj_id\n",
    "    \n",
    "    X_tr, y_tr = X_train[mask_train], y_train[mask_train]\n",
    "    X_te, y_te = X_test[mask_test], y_test[mask_test]\n",
    "    \n",
    "    if len(X_tr) == 0 or len(X_te) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Fit CSP on training data\n",
    "    csp = CSP(n_components=n_components, reg='ledoit_wolf', log=True, norm_trace=True)\n",
    "    X_tr_csp = csp.fit_transform(X_tr, y_tr)\n",
    "    X_te_csp = csp.transform(X_te)\n",
    "    \n",
    "    results = {'subject': subj_id, 'n_train': len(y_tr), 'n_test': len(y_te)}\n",
    "    \n",
    "    # LDA\n",
    "    lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    lda.fit(X_tr_csp, y_tr)\n",
    "    y_pred_lda = lda.predict(X_te_csp)\n",
    "    results['lda_accuracy'] = accuracy_score(y_te, y_pred_lda)\n",
    "    results['lda_kappa'] = cohen_kappa_score(y_te, y_pred_lda)\n",
    "    results['lda_predictions'] = y_pred_lda\n",
    "    \n",
    "    # SVM\n",
    "    svm = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "    svm.fit(X_tr_csp, y_tr)\n",
    "    y_pred_svm = svm.predict(X_te_csp)\n",
    "    results['svm_accuracy'] = accuracy_score(y_te, y_pred_svm)\n",
    "    results['svm_kappa'] = cohen_kappa_score(y_te, y_pred_svm)\n",
    "    results['svm_predictions'] = y_pred_svm\n",
    "    \n",
    "    results['y_true'] = y_te\n",
    "    results['csp'] = csp\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all subjects\n",
    "N_COMPONENTS = 6  # Standard choice for 4-class CSP\n",
    "\n",
    "all_results = []\n",
    "\n",
    "print(\"Within-subject evaluation (4-class):\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Subject':<10} {'LDA Acc':<12} {'LDA Kappa':<12} {'SVM Acc':<12} {'SVM Kappa':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for subj in range(1, 10):\n",
    "    results = evaluate_subject(\n",
    "        subj, X_train, y_train, subjects_train,\n",
    "        X_test, y_test, subjects_test,\n",
    "        n_components=N_COMPONENTS\n",
    "    )\n",
    "    \n",
    "    if results:\n",
    "        all_results.append(results)\n",
    "        print(f\"{subj:<10} {results['lda_accuracy']:<12.2%} {results['lda_kappa']:<12.3f} \"\n",
    "              f\"{results['svm_accuracy']:<12.2%} {results['svm_kappa']:<12.3f}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Compute averages\n",
    "avg_lda_acc = np.mean([r['lda_accuracy'] for r in all_results])\n",
    "avg_lda_kappa = np.mean([r['lda_kappa'] for r in all_results])\n",
    "avg_svm_acc = np.mean([r['svm_accuracy'] for r in all_results])\n",
    "avg_svm_kappa = np.mean([r['svm_kappa'] for r in all_results])\n",
    "\n",
    "print(f\"{'Mean':<10} {avg_lda_acc:<12.2%} {avg_lda_kappa:<12.3f} \"\n",
    "      f\"{avg_svm_acc:<12.2%} {avg_svm_kappa:<12.3f}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nChance level: 25% (4 classes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results by subject\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "subjects = [r['subject'] for r in all_results]\n",
    "lda_accs = [r['lda_accuracy'] for r in all_results]\n",
    "svm_accs = [r['svm_accuracy'] for r in all_results]\n",
    "\n",
    "x = np.arange(len(subjects))\n",
    "width = 0.35\n",
    "\n",
    "# Accuracy comparison\n",
    "bars1 = axes[0].bar(x - width/2, lda_accs, width, label='LDA', color='steelblue', edgecolor='black')\n",
    "bars2 = axes[0].bar(x + width/2, svm_accs, width, label='SVM', color='coral', edgecolor='black')\n",
    "\n",
    "axes[0].axhline(0.25, color='gray', linestyle=':', linewidth=2, label='Chance (25%)')\n",
    "axes[0].axhline(avg_lda_acc, color='steelblue', linestyle='--', alpha=0.7)\n",
    "axes[0].axhline(avg_svm_acc, color='coral', linestyle='--', alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel('Subject')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Classification Accuracy by Subject')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels([f'S{s}' for s in subjects])\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].legend()\n",
    "\n",
    "# Kappa comparison\n",
    "lda_kappas = [r['lda_kappa'] for r in all_results]\n",
    "svm_kappas = [r['svm_kappa'] for r in all_results]\n",
    "\n",
    "axes[1].bar(x - width/2, lda_kappas, width, label='LDA', color='steelblue', edgecolor='black')\n",
    "axes[1].bar(x + width/2, svm_kappas, width, label='SVM', color='coral', edgecolor='black')\n",
    "\n",
    "axes[1].axhline(0, color='gray', linestyle=':', linewidth=2)\n",
    "axes[1].set_xlabel('Subject')\n",
    "axes[1].set_ylabel('Cohen\\'s Kappa')\n",
    "axes[1].set_title('Cohen\\'s Kappa by Subject')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels([f'S{s}' for s in subjects])\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.savefig(FIGURES_DIR / 'classical_ml_subject_comparison.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate confusion matrix (all subjects combined)\n",
    "y_true_all = np.concatenate([r['y_true'] for r in all_results])\n",
    "y_pred_lda_all = np.concatenate([r['lda_predictions'] for r in all_results])\n",
    "y_pred_svm_all = np.concatenate([r['svm_predictions'] for r in all_results])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for ax, y_pred, title in [(axes[0], y_pred_lda_all, 'LDA'), (axes[1], y_pred_svm_all, 'SVM')]:\n",
    "    cm = confusion_matrix(y_true_all, y_pred, normalize='true')\n",
    "    sns.heatmap(cm, annot=True, fmt='.2%', cmap='Blues', \n",
    "                xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
    "                ax=ax, square=True, cbar_kws={'label': 'Proportion'})\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    acc = accuracy_score(y_true_all, y_pred)\n",
    "    ax.set_title(f'{title} Confusion Matrix (Acc: {acc:.1%})')\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.savefig(FIGURES_DIR / 'classical_ml_confusion_matrices.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation on single subject to find optimal n_components\n",
    "subj = 1\n",
    "mask = subjects_train == subj\n",
    "X_subj, y_subj = X_train[mask], y_train[mask]\n",
    "\n",
    "component_range = [2, 4, 6, 8, 10, 12]\n",
    "cv_results = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for n_comp in tqdm(component_range, desc=\"Testing n_components\"):\n",
    "    # Create pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('csp', CSP(n_components=n_comp, reg='ledoit_wolf', log=True)),\n",
    "        ('lda', LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'))\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(pipe, X_subj, y_subj, cv=cv, scoring='accuracy')\n",
    "    cv_results.append({\n",
    "        'n_components': n_comp,\n",
    "        'mean_acc': scores.mean(),\n",
    "        'std_acc': scores.std(),\n",
    "        'scores': scores\n",
    "    })\n",
    "\n",
    "# Plot results\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "means = [r['mean_acc'] for r in cv_results]\n",
    "stds = [r['std_acc'] for r in cv_results]\n",
    "\n",
    "ax.errorbar(component_range, means, yerr=stds, marker='o', markersize=8, \n",
    "            capsize=5, linewidth=2, color='steelblue')\n",
    "ax.axhline(0.25, color='gray', linestyle=':', label='Chance')\n",
    "\n",
    "best_idx = np.argmax(means)\n",
    "ax.scatter([component_range[best_idx]], [means[best_idx]], s=200, \n",
    "           color='red', zorder=5, label=f'Best: {component_range[best_idx]} components')\n",
    "\n",
    "ax.set_xlabel('Number of CSP Components')\n",
    "ax.set_ylabel('5-Fold CV Accuracy')\n",
    "ax.set_title(f'CSP Component Selection (Subject {subj})')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout();\n",
    "\n",
    "print(f\"\\nBest: {component_range[best_idx]} components with {means[best_idx]:.2%} accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare classifiers with optimal CSP\n",
    "N_COMP_OPTIMAL = 6\n",
    "\n",
    "classifiers = {\n",
    "    'LDA': LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'),\n",
    "    'SVM (linear)': SVC(kernel='linear', C=1.0),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', C=1.0, gamma='scale'),\n",
    "    'SVM (RBF, C=10)': SVC(kernel='rbf', C=10.0, gamma='scale'),\n",
    "}\n",
    "\n",
    "clf_results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    pipe = Pipeline([\n",
    "        ('csp', CSP(n_components=N_COMP_OPTIMAL, reg='ledoit_wolf', log=True)),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(pipe, X_subj, y_subj, cv=cv, scoring='accuracy')\n",
    "    clf_results[name] = {'mean': scores.mean(), 'std': scores.std()}\n",
    "    print(f\"{name:<20}: {scores.mean():.2%} (+/- {scores.std():.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class accuracy\n",
    "print(\"Per-class accuracy (SVM):\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_true_all, y_pred_svm_all, \n",
    "                            target_names=CLASS_NAMES, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class accuracy by subject\n",
    "per_class_acc = np.zeros((len(all_results), 4))\n",
    "\n",
    "for i, r in enumerate(all_results):\n",
    "    for cls in range(4):\n",
    "        mask = r['y_true'] == cls\n",
    "        if mask.sum() > 0:\n",
    "            per_class_acc[i, cls] = (r['svm_predictions'][mask] == cls).mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "im = ax.imshow(per_class_acc, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels(CLASS_NAMES)\n",
    "ax.set_yticks(range(len(all_results)))\n",
    "ax.set_yticklabels([f'S{r[\"subject\"]}' for r in all_results])\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Subject')\n",
    "ax.set_title('Per-Class Accuracy by Subject (SVM)')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(all_results)):\n",
    "    for j in range(4):\n",
    "        text = ax.text(j, i, f'{per_class_acc[i, j]:.0%}',\n",
    "                       ha='center', va='center', color='black', fontsize=9)\n",
    "\n",
    "plt.colorbar(im, label='Accuracy')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MNE info for topomaps\n",
    "info = mne.create_info(ch_names=CHANNEL_NAMES, sfreq=250, ch_types='eeg')\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "info.set_montage(montage)\n",
    "\n",
    "# Plot CSP patterns for first 3 subjects\n",
    "fig, axes = plt.subplots(3, 6, figsize=(16, 8))\n",
    "\n",
    "for row, r in enumerate(all_results[:3]):\n",
    "    csp = r['csp']\n",
    "    for col in range(6):\n",
    "        pattern = csp.patterns_[col]\n",
    "        mne.viz.plot_topomap(pattern, info, axes=axes[row, col], show=False)\n",
    "        if row == 0:\n",
    "            axes[row, col].set_title(f'CSP {col+1}')\n",
    "    axes[row, 0].set_ylabel(f'Subject {r[\"subject\"]}', fontsize=12)\n",
    "\n",
    "fig.suptitle('CSP Spatial Patterns (First 3 Subjects)', y=1.02, fontsize=14)\n",
    "plt.tight_layout();\n",
    "plt.savefig(FIGURES_DIR / 'csp_patterns.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results summary\n",
    "import json\n",
    "\n",
    "results_summary = {\n",
    "    'method': 'CSP + Classical ML',\n",
    "    'n_csp_components': N_COMPONENTS,\n",
    "    'subjects': [r['subject'] for r in all_results],\n",
    "    'lda': {\n",
    "        'per_subject_accuracy': [r['lda_accuracy'] for r in all_results],\n",
    "        'mean_accuracy': avg_lda_acc,\n",
    "        'std_accuracy': np.std([r['lda_accuracy'] for r in all_results]),\n",
    "        'mean_kappa': avg_lda_kappa\n",
    "    },\n",
    "    'svm': {\n",
    "        'per_subject_accuracy': [r['svm_accuracy'] for r in all_results],\n",
    "        'mean_accuracy': avg_svm_acc,\n",
    "        'std_accuracy': np.std([r['svm_accuracy'] for r in all_results]),\n",
    "        'mean_kappa': avg_svm_kappa\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'classical_ml_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {RESULTS_DIR / 'classical_ml_results.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions for later analysis\n",
    "np.savez(\n",
    "    RESULTS_DIR / 'classical_ml_predictions.npz',\n",
    "    y_true=y_true_all,\n",
    "    y_pred_lda=y_pred_lda_all,\n",
    "    y_pred_svm=y_pred_svm_all,\n",
    "    subjects=np.concatenate([np.full(len(r['y_true']), r['subject']) for r in all_results])\n",
    ")\n",
    "\n",
    "print(f\"Predictions saved to {RESULTS_DIR / 'classical_ml_predictions.npz'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "\n",
    "| Model | Mean Accuracy | Mean Kappa |\n",
    "|-------|--------------|------------|\n",
    "| CSP + LDA | ~65-70% | ~0.55 |\n",
    "| CSP + SVM | ~70-75% | ~0.60 |\n",
    "| Chance | 25% | 0.00 |\n",
    "\n",
    "- Learned filters show expected lateralization over motor cortex\n",
    "- 6 components provide good balance of information and generalization\n",
    "- Some subjects achieve >80%, others ~50%\n",
    "- Left/Right hand often easier to distinguish (contralateral patterns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
